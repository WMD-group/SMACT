{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the dimension reduction techniques to reduce the dimension of the data. We will use the following techniques:\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "- t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- Uniform Manifold Approximation and Projection (UMAP)\n",
    "\n",
    "we will make composional embedding created by element embeddings, as follows:\n",
    "\n",
    "(Please refer to [ElementEmbeddings](https://wmd-group.github.io/ElementEmbeddings/0.4/reference/) for the details of element embedding)\n",
    "\n",
    "- Magpie\n",
    "- Mat2Vec\n",
    "- Megnet16\n",
    "- Skipatom\n",
    "- Oliynyk\n",
    "- random_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Element Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will make compositional embedding created by element embeddings using the ElementEmbeddings package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ElementEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from elementembeddings.composition import CompositionalEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_names = [\n",
    "    \"magpie\",\n",
    "    \"mat2vec\",\n",
    "    \"megnet16\",\n",
    "    \"skipatom\",\n",
    "    \"oliynyk\",\n",
    "    \"random_200\",\n",
    "]\n",
    "\n",
    "reducers = [\"pca\", \"tsne\", \"umap\"]\n",
    "\n",
    "# set save directory\n",
    "save_dir = Path(\"data/binary/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category = pd.read_pickle(save_dir / \"df_binary_category.pkl\")\n",
    "df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "n_samples = 3000\n",
    "\n",
    "dict_label = {\n",
    "    \"standard\": 0,\n",
    "    \"missing\": 1,\n",
    "    \"interesting\": 2,\n",
    "    \"unlikely\": 3,\n",
    "}\n",
    "labels = [\"standard\", \"missing\", \"interesting\", \"unlikely\"]\n",
    "list_df_sample = []\n",
    "for label in labels:\n",
    "    m = df_category[\"label\"] == label\n",
    "    df = df_category[m].sample(\n",
    "        n=min(n_samples, len(df_category[m])),\n",
    "        random_state=42,\n",
    "    )\n",
    "    list_df_sample.append(df)\n",
    "df_sample = pd.concat(list_df_sample)\n",
    "# save sampled data\n",
    "df_sample.to_pickle(save_dir / \"df_binary_sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(formula, embedding=\"magpie\", stats=\"mean\"):\n",
    "    \"\"\"\n",
    "    Computes a compositional embedding for a given chemical formula or a list of chemical formulas.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    formula : str or iterable\n",
    "\n",
    "    embedding : str, optional\n",
    "        The type of embedding to compute. Must be one of ['magpie', 'mat2vec', 'megnet16', 'skipatom', 'oliynyk', 'random_200'].\n",
    "        Default is 'magpie'.\n",
    "    stats : str, optional\n",
    "        The type of statistics to compute for the embedding. Must be one of\n",
    "        [\"mean\", \"variance\", \"minpool\", \"maxpool\", \"range\", \"sum\", \"geometric_mean\", \"harmonic_mean\"].\n",
    "        Default is 'mean'.\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        1D array when formula is a string, 2D array when formula is a list of strings.\n",
    "    \"\"\"\n",
    "    if isinstance(formula, str):\n",
    "        formula = [formula]\n",
    "    elif isinstance(formula, Iterable):\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError(\"formula must be a string or a list of strings\")\n",
    "\n",
    "    # get embedding dimension\n",
    "    embedding_dim = CompositionalEmbedding(\n",
    "        \"\", embedding=embedding\n",
    "    ).embedding_dim\n",
    "\n",
    "    # compute embedding\n",
    "    embeddings = []\n",
    "    for f in tqdm(formula):\n",
    "        try:\n",
    "            compositional_embedding = CompositionalEmbedding(\n",
    "                f, embedding=embedding\n",
    "            )\n",
    "            embeddings.append(\n",
    "                compositional_embedding.feature_vector(stats=stats)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # the exception is raised when the embedding doesn't support the element\n",
    "            embeddings.append(np.full(embedding_dim, np.nan))\n",
    "\n",
    "    # concatenate the embedded vectors\n",
    "    embeddings = np.stack(embeddings, axis=0).squeeze()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory to save the embeddings\n",
    "(save_dir / \"embeddings\").mkdir(parents=True, exist_ok=True)\n",
    "# save the embeddings\n",
    "for name in embedding_names:\n",
    "    print(f\"Computing {name} embeddings\")\n",
    "    embeddings = get_embedding(df_sample.index, embedding=name)\n",
    "    df_embeddings = pd.DataFrame(embeddings, index=df_sample.index)\n",
    "    df_embeddings = df_embeddings.dropna(axis=0)\n",
    "    df_embeddings.to_pickle(save_dir / \"embeddings\" / f\"embeddings_{name}.pkl\")\n",
    "    print(\n",
    "        f\"Saved {name} embeddings with shape {df_embeddings.shape} to {save_dir / 'embeddings' / f'embeddings_{name}.pkl'}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the dimension reduction techniques to reduce the dimension of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install umap-learn==0.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(\n",
    "    embeddings,\n",
    "    reducer=\"pca\",\n",
    "    n_components=2,\n",
    "    save_dir=None,\n",
    "    file_name=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs dimensionality reduction on the given embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    embeddings : pandas.DataFrame\n",
    "        The embeddings to reduce.\n",
    "    reducer : str, optional\n",
    "        The dimensionality reduction algorithm to use. Must be one of ['pca', 'tsne', 'umap'].\n",
    "        Default is 'pca'.\n",
    "    n_components : int, optional\n",
    "        The number of components to reduce to. Default is 2.\n",
    "    save_dir : str, optional\n",
    "        The directory to save the reduced embeddings. Default is None.\n",
    "    file_name : str, optional\n",
    "        The file name to save the reduced embeddings. Default is None.\n",
    "    **kwargs : dict, optional\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        The reduced embeddings.\n",
    "    \"\"\"\n",
    "    if reducer == \"pca\":\n",
    "        reducer = PCA(n_components=n_components, **kwargs)\n",
    "    elif reducer == \"tsne\":\n",
    "        reducer = TSNE(n_components=n_components, **kwargs)\n",
    "    elif reducer == \"umap\":\n",
    "        reducer = UMAP(n_components=n_components, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"reducer must be one of ['pca', 'tsne', 'umap']\")\n",
    "\n",
    "    reduced_embeddings = reducer.fit_transform(embeddings.values)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        save_dir = Path(save_dir)\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "        if file_name is None:\n",
    "            file_name = f\"reduced_embeddings_{reducer.__class__.__name__}.pkl\"\n",
    "        else:\n",
    "            file_name = f\"{file_name}.pkl\"\n",
    "        pd.DataFrame(reduced_embeddings, index=embeddings.index).to_pickle(\n",
    "            save_dir / file_name\n",
    "        )\n",
    "        print(f\"Saved reduced embeddings to {save_dir / file_name}\")\n",
    "    return reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory to save the reduced embeddings\n",
    "(save_dir / \"reduced_embeddings_2d\").mkdir(parents=True, exist_ok=True)\n",
    "# calculate the reduced embeddings\n",
    "silhouette_scores = {}\n",
    "for name in embedding_names:\n",
    "    for reducer in reducers:\n",
    "        print(f\"Computing {name} {reducer} embeddings\")\n",
    "\n",
    "        embeddings = pd.read_pickle(\n",
    "            save_dir / \"embeddings\" / f\"embeddings_{name}.pkl\"\n",
    "        )\n",
    "\n",
    "        reduced_embeddings = dimension_reduction(\n",
    "            embeddings,\n",
    "            reducer=reducer,\n",
    "            n_components=2,\n",
    "            save_dir=save_dir / \"reduced_embeddings_2d\",\n",
    "            file_name=f\"{reducer}_{name}\",\n",
    "            random_state=42,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization of the Reduced Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_embedding import plot_reducers_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category = pd.read_pickle(save_dir / \"df_binary_category.pkl\")\n",
    "df_category[\"formula\"] = df_category.index\n",
    "embedding_dir = Path(save_dir / \"reduced_embeddings_2d/\")\n",
    "save_path = save_dir / \"plot_binary.jpg\"  # save path for the plot\n",
    "fig = plot_reducers_embeddings(\n",
    "    df_category,\n",
    "    reducers,\n",
    "    embedding_names,\n",
    "    embedding_dir,\n",
    "    symbol=\"circle\",\n",
    "    title=\"Compositional space for binary compounds\",\n",
    "    save_path=save_path,\n",
    ")\n",
    "# check the plot in save_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
